{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":2491748,"sourceType":"datasetVersion","datasetId":1500837}],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        os.path.join(dirname, filename)\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2024-11-25T23:37:58.473121Z","iopub.execute_input":"2024-11-25T23:37:58.473412Z","iopub.status.idle":"2024-11-25T23:39:38.139458Z","shell.execute_reply.started":"2024-11-25T23:37:58.473355Z","shell.execute_reply":"2024-11-25T23:39:38.138751Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import json\nimport os\nimport random\nimport matplotlib.pyplot as plt\nimport cv2\n\n# Load labels from JSON file\nwith open('/kaggle/input/imagenet100/Labels.json', 'r') as f:\n    labels = json.load(f)\n\n# Create a mapping from class ID to class name\nid_to_class = {str(k): v for k, v in labels.items()}\n\n# Function to display an image with its label\ndef show_image_with_label(image_path, label):\n    image = cv2.imread(image_path)\n    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n    plt.imshow(image)\n    plt.title(f'Label: {label}')\n    plt.axis('off')\n    plt.show()\n\n# Directories containing the images\nbase_train_dir = '/kaggle/input/imagenet100'\nval_dir = os.path.join(base_train_dir, 'val.X')\ntrain_dirs = [os.path.join(base_train_dir, f'train.X{i}') for i in range(1, 5)]\n\n# Helper function to get a random sample of images from a directory\ndef get_random_images(data_dirs, num_samples=5):\n    images = []\n    all_files = []\n    for data_dir in data_dirs:\n        for label_id in os.listdir(data_dir):\n            class_name = id_to_class.get(label_id, 'Unknown')\n            files = os.listdir(os.path.join(data_dir, label_id))\n            all_files.extend([(os.path.join(data_dir, label_id, filename), class_name) for filename in files])\n\n    selected_files = random.sample(all_files, num_samples)\n    for image_path, class_name in selected_files:\n        images.append((image_path, class_name))\n    return images\n\n# Get random images from validation set\nval_images = get_random_images([val_dir], 5)\n\n# Get random images from all training directories\ntrain_images = get_random_images(train_dirs, 5)\n\n# Display random validation images\nprint(\"Random Validation Images:\")\nfor image_path, label in val_images:\n    show_image_with_label(image_path, label)\n\n# Display random training images\nprint(\"Random Training Images:\")\nfor image_path, label in train_images:\n    show_image_with_label(image_path, label)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-25T23:39:38.140838Z","iopub.execute_input":"2024-11-25T23:39:38.141236Z","iopub.status.idle":"2024-11-25T23:39:41.182385Z","shell.execute_reply.started":"2024-11-25T23:39:38.141209Z","shell.execute_reply":"2024-11-25T23:39:41.181590Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nimport torchvision\nimport torchvision.transforms as transforms\nimport torchvision.datasets as datasets\nimport torch.nn as nn\nimport torch.optim as optim\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom PIL import Image\n\n\n# Check for GPU\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-25T23:41:42.449346Z","iopub.execute_input":"2024-11-25T23:41:42.449741Z","iopub.status.idle":"2024-11-25T23:41:42.456103Z","shell.execute_reply.started":"2024-11-25T23:41:42.449692Z","shell.execute_reply":"2024-11-25T23:41:42.455041Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Define transforms for ImageNet100\ntransform = transforms.Compose([\n    transforms.Resize(256),  # Resize the shorter side to 256\n    transforms.CenterCrop(224),  # Center crop to 224x224\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # ImageNet normalization\n])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-25T23:41:42.713647Z","iopub.execute_input":"2024-11-25T23:41:42.714507Z","iopub.status.idle":"2024-11-25T23:41:42.720098Z","shell.execute_reply.started":"2024-11-25T23:41:42.714460Z","shell.execute_reply":"2024-11-25T23:41:42.719158Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from torch.utils.data import Dataset\n\n# Create a custom dataset class\nclass MultiFolderDataset(Dataset):\n    def __init__(self, folders, transform=None):\n        self.samples = []\n        self.transform = transform\n        for folder in folders:\n            for label_id in os.listdir(folder):\n                class_name = id_to_class.get(label_id, 'Unknown')\n                files = os.listdir(os.path.join(folder, label_id))\n                self.samples.extend([(os.path.join(folder, label_id, filename), label_id) for filename in files])\n        self.class_to_idx = {cls_name: i for i, cls_name in enumerate(sorted(id_to_class.keys()))}\n\n    def __len__(self):\n        return len(self.samples)\n\n    def __getitem__(self, idx):\n        path, label = self.samples[idx]\n        image = Image.open(path).convert(\"RGB\")\n        if self.transform is not None:\n            image = self.transform(image)\n        label = self.class_to_idx[label]\n        return image, label","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-25T23:41:42.868085Z","iopub.execute_input":"2024-11-25T23:41:42.868587Z","iopub.status.idle":"2024-11-25T23:41:42.875537Z","shell.execute_reply.started":"2024-11-25T23:41:42.868557Z","shell.execute_reply":"2024-11-25T23:41:42.874626Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torchvision.datasets as datasets\n# Creating the Datasets\ntrain_dataset = MultiFolderDataset(train_dirs, transform=transform)\nval_dataset = datasets.ImageFolder(val_dir, transform=transform)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-25T23:41:43.137677Z","iopub.execute_input":"2024-11-25T23:41:43.137970Z","iopub.status.idle":"2024-11-25T23:41:44.979219Z","shell.execute_reply.started":"2024-11-25T23:41:43.137944Z","shell.execute_reply":"2024-11-25T23:41:44.978271Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# DataLoaders\nbatch_size = 64\ntrain_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4)\nval_loader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=4)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-25T23:41:44.980647Z","iopub.execute_input":"2024-11-25T23:41:44.980924Z","iopub.status.idle":"2024-11-25T23:41:44.987232Z","shell.execute_reply.started":"2024-11-25T23:41:44.980898Z","shell.execute_reply":"2024-11-25T23:41:44.986429Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Check dataset\nprint(f\"Number of training images: {len(train_dataset)}\")\nprint(f\"Number of validation images: {len(val_dataset)}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-25T23:41:44.988358Z","iopub.execute_input":"2024-11-25T23:41:44.988633Z","iopub.status.idle":"2024-11-25T23:41:45.005275Z","shell.execute_reply.started":"2024-11-25T23:41:44.988609Z","shell.execute_reply":"2024-11-25T23:41:45.004642Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Import pre-trained AlexNet\nmodel = torchvision.models.alexnet(pretrained=True)\n\n# Modify the classifier for ImageNet100\nmodel.classifier[6] = nn.Linear(4096, 100)\n\n# Send model to device\nmodel = model.to(device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-25T23:42:03.016956Z","iopub.execute_input":"2024-11-25T23:42:03.017666Z","iopub.status.idle":"2024-11-25T23:42:05.270144Z","shell.execute_reply.started":"2024-11-25T23:42:03.017618Z","shell.execute_reply":"2024-11-25T23:42:05.269146Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from tqdm import tqdm\n\n# Loss function and optimizer\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), lr=0.001)\n\n# Training loop with tqdm\nnum_epochs = 1\n\nfor epoch in range(num_epochs):\n    model.train()\n    running_loss = 0.0\n\n    # Wrap the training DataLoader with tqdm\n    progress_bar = tqdm(enumerate(train_loader), total=len(train_loader), desc=f\"Epoch {epoch+1}/{num_epochs}\")\n\n    for i, (inputs, labels) in progress_bar:\n        inputs, labels = inputs.to(device), labels.to(device)\n\n        # Zero gradients\n        optimizer.zero_grad()\n\n        # Forward pass\n        outputs = model(inputs)\n        loss = criterion(outputs, labels)\n\n        # Backward pass and optimization\n        loss.backward()\n        optimizer.step()\n\n        # Update running loss\n        running_loss += loss.item()\n\n        # Update tqdm progress bar description\n        progress_bar.set_postfix({\"Loss\": running_loss / (i + 1)})\n\n    print(f\"Epoch [{epoch+1}/{num_epochs}] completed. Loss: {running_loss / len(train_loader):.4f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-25T23:42:59.070279Z","iopub.execute_input":"2024-11-25T23:42:59.070734Z","iopub.status.idle":"2024-11-25T23:50:34.700234Z","shell.execute_reply.started":"2024-11-25T23:42:59.070689Z","shell.execute_reply":"2024-11-25T23:50:34.699192Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Evaluation loop with tqdm\nmodel.eval()\ncorrect = 0\ntotal = 0\n\n# Wrap the validation DataLoader with tqdm\nprogress_bar = tqdm(enumerate(val_loader), total=len(val_loader), desc=\"Evaluating\")\n\nwith torch.no_grad():\n    for i, (inputs, labels) in progress_bar:\n        inputs, labels = inputs.to(device), labels.to(device)\n\n        # Forward pass\n        outputs = model(inputs)\n        _, predicted = torch.max(outputs, 1)\n        total += labels.size(0)\n        correct += (predicted == labels).sum().item()\n\n        # Update tqdm progress bar description\n        progress_bar.set_postfix({\"Accuracy\": 100 * correct / total})\n\nprint(f\"Accuracy on the validation set: {100 * correct / total:.2f}%\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-25T23:50:34.702459Z","iopub.execute_input":"2024-11-25T23:50:34.703306Z","iopub.status.idle":"2024-11-25T23:50:52.165884Z","shell.execute_reply.started":"2024-11-25T23:50:34.703259Z","shell.execute_reply":"2024-11-25T23:50:52.164882Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}